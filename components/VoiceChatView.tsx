import React, { useState, useEffect, useRef, useCallback } from 'react';
import { GoogleGenAI, LiveServerMessage, Modality, Session, Blob } from "@google/genai";
import { createBlob, decode, decodeAudioData } from '../utils/audioUtils';

const AstronautAvatar: React.FC<{ isSpeaking: boolean, isListening: boolean }> = ({ isSpeaking, isListening }) => {
    return (
        <div className="relative w-48 h-48 sm:w-64 sm:h-64 mx-auto">
            <div className={`absolute inset-0 rounded-full bg-yellow-400 transition-all duration-500 ${isSpeaking ? 'animate-ping-slow opacity-75' : 'opacity-0'}`}></div>
            <div className={`absolute inset-0 rounded-full border-4 border-dashed border-teal-400 transition-all duration-500 ${isListening ? 'animate-spin-slow opacity-100' : 'opacity-0'}`}></div>
            <div className="relative z-10 w-full h-full bg-gray-700 rounded-full flex items-center justify-center text-8xl sm:text-9xl border-4 border-gray-600">
                ğŸ§‘â€ğŸš€
            </div>
        </div>
    );
};

const VoiceChatView: React.FC<{ onBack: () => void }> = ({ onBack }) => {
    const [status, setStatus] = useState('Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ø³...');
    const [error, setError] = useState<string | null>(null);
    const [isSpeaking, setIsSpeaking] = useState(false);
    const [isListening, setIsListening] = useState(false);
    const [userTranscript, setUserTranscript] = useState('');
    const [modelTranscript, setModelTranscript] = useState('');

    const sessionPromiseRef = useRef<Promise<Session> | null>(null);
    
    const cleanupRef = useRef<(() => void) | null>(null);

    const startConversation = useCallback(async () => {
        setError(null);
        setStatus('Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ†...');

        const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
        // Fix: Cast window to `any` to support `webkitAudioContext` for older browsers without TypeScript errors.
        const inputAudioContext = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 16000 });
        // Fix: Cast window to `any` to support `webkitAudioContext` for older browsers without TypeScript errors.
        const outputAudioContext = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 24000 });
        const outputNode = outputAudioContext.createGain();
        outputNode.connect(outputAudioContext.destination);
        const sources = new Set<AudioBufferSourceNode>();
        let nextStartTime = 0;
        let stream: MediaStream | null = null;
        let scriptProcessor: ScriptProcessorNode | null = null;
        let mediaSource: MediaStreamAudioSourceNode | null = null;
        
        const cleanup = () => {
          if (cleanupRef.current === cleanup) {
              inputAudioContext.close();
              outputAudioContext.close();
              if (stream) {
                  stream.getTracks().forEach(track => track.stop());
              }
              if(scriptProcessor) {
                  scriptProcessor.disconnect();
              }
              if(mediaSource) {
                  mediaSource.disconnect();
              }
              sessionPromiseRef.current?.then(session => session.close());
              setIsListening(false);
              setIsSpeaking(false);
              console.log("Cleanup complete.");
          }
        };
        cleanupRef.current = cleanup;

        try {
            stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    sampleRate: 16000,
                    channelCount: 1,
                }
            });
            
            setStatus('Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ù‚Ø±Ø§Ø±ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ ÙØ¶Ø§...');

            const systemInstruction = `
Ø´Ù…Ø§ Ú©Ø§Ù¾ÛŒØªØ§Ù† Ú©ÛŒØ§Ù†ØŒ ÛŒÚ© ÙØ¶Ø§Ù†ÙˆØ±Ø¯ Ø´Ø¬Ø§Ø¹ Ùˆ Ù…Ø§Ø¬Ø±Ø§Ø¬Ùˆ Ù‡Ø³ØªÛŒØ¯. Ø´Ø®ØµÛŒØª Ø´Ù…Ø§ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø«Ø§Ø¨Øª Ø§Ø³Øª.

**Ø¯Ø§Ø³ØªØ§Ù† Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø´Ù…Ø§:**
- **Ù†Ø§Ù…:** Ú©Ø§Ù¾ÛŒØªØ§Ù† Ú©ÛŒØ§Ù†
- **Ø´Ø®ØµÛŒØª:** Ø´Ø¬Ø§Ø¹ØŒ Ø®ÙˆØ´â€ŒØ¨ÛŒÙ†ØŒ Ø´ÙˆØ®â€ŒØ·Ø¨Ø¹ØŒ Ø¨ÛŒâ€ŒÙ†Ù‡Ø§ÛŒØª Ú©Ù†Ø¬Ú©Ø§Ùˆ Ùˆ Ø¹Ø§Ø´Ù‚ ÙØ¶Ø§. Ø´Ù…Ø§ Ø§Ø² ØªÙˆØ¶ÛŒØ­ Ù…ÙØ§Ù‡ÛŒÙ… Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø³Ø§Ø¯Ù‡ Ùˆ Ù‡ÛŒØ¬Ø§Ù†â€ŒØ§Ù†Ú¯ÛŒØ² Ù„Ø°Øª Ù…ÛŒâ€ŒØ¨Ø±ÛŒØ¯ Ùˆ Ø¯Ø± Ù‡Ù…Ù‡ Ú†ÛŒØ² Ø´Ú¯ÙØªÛŒ Ù…ÛŒâ€ŒØ¨ÛŒÙ†ÛŒØ¯.
- **Ø³ÙÛŒÙ†Ù‡ ÙØ¶Ø§ÛŒÛŒ:** Ø´Ù…Ø§ ÙØ±Ù…Ø§Ù†Ø¯Ù‡ Ø³ÙÛŒÙ†Ù‡ Ø§Ú©ØªØ´Ø§ÙÛŒ "Ú©Ø§ÙˆØ´-Û±" Ù‡Ø³ØªÛŒØ¯ØŒ ÛŒÚ© Ø³ÙÛŒÙ†Ù‡ Ø²ÛŒØ¨Ø§ Ú©Ù‡ Ø¨Ø§ Ø§Ù†Ø±Ú˜ÛŒ Ø®ÙˆØ±Ø´ÛŒØ¯ÛŒ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
- **Ù‡Ù…Ú©Ø§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ:** Ø´Ù…Ø§ ÛŒÚ© Ù‡Ù…Ú©Ø§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ù‡ Ù†Ø§Ù… "Ø¯Ø§Ù†Ø§" Ø¯Ø§Ø±ÛŒØ¯ Ú©Ù‡ Ú¯Ø§Ù‡ÛŒ Ø§ÙˆÙ‚Ø§Øª Ø¯Ø± Ù…Ú©Ø§Ù„Ù…Ø§Øª Ø¨Ù‡ Ø§Ùˆ Ø§Ø´Ø§Ø±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ (Ù…Ø«Ù„Ø§Ù‹: "Ø¯Ø§Ù†Ø§ Ù…ÛŒÚ¯Ù‡ Ø¯Ø§Ø±ÛŒÙ… Ø¨Ù‡ ÛŒÚ© Ø³Ø­Ø§Ø¨ÛŒ Ù†Ø²Ø¯ÛŒÚ© Ù…ÛŒØ´ÛŒÙ…!").
- **Ù…Ø§Ù…ÙˆØ±ÛŒØª ÙØ¹Ù„ÛŒ:** Ø´Ù…Ø§ Ø¯Ø± Ø­Ø§Ù„ Ù†Ù‚Ø´Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ Ø§Ø² Ø¨Ø®Ø´ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡â€ŒØ§ÛŒ Ø§Ø² Ú©Ù‡Ú©Ø´Ø§Ù† Ø¨Ù‡ Ù†Ø§Ù… "Ø¨Ø®Ø´ Ø§Ø¯ÛŒØ¨" Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¨Ù‡ Ù¾Ø¯ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©ÛŒÙ‡Ø§Ù†ÛŒ Ø¹Ø¬ÛŒØ¨ Ùˆ Ø²ÛŒØ¨Ø§ÛŒØ´ Ù…Ø¹Ø±ÙˆÙ Ø§Ø³Øª.
- **Ø®Ø§Ø·Ø±Ù‡ ÙˆÛŒÚ˜Ù‡:** Ø®Ø§Ø·Ø±Ù‡ Ù…ÙˆØ±Ø¯ Ø¹Ù„Ø§Ù‚Ù‡ Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ ØªØ¹Ø±ÛŒÙ Ú©Ø±Ø¯Ù†ØŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø±ÙˆÛŒ Ø³ÛŒØ§Ø±Ù‡ "Ø´Ø¨â€ŒØªØ§Ø¨-Û·" ÙØ±ÙˆØ¯ Ø¢Ù…Ø¯ÛŒØ¯ Ùˆ Ø¬Ù†Ú¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ø§Ø² Ù‚Ø§Ø±Ú†â€ŒÙ‡Ø§ÛŒ ØºÙˆÙ„â€ŒÙ¾ÛŒÚ©Ø± Ùˆ Ø¯Ø±Ø®Ø´Ø§Ù† Ø±Ø§ Ú©Ø´Ù Ú©Ø±Ø¯ÛŒØ¯ Ùˆ Ø¨Ø§ Ù…ÙˆØ¬ÙˆØ¯Ø§Øª Ú©ÙˆÚ†Ú© Ùˆ Ù¾Ø´Ù…Ø§Ù„ÙˆÛŒÛŒ Ø¨Ù‡ Ù†Ø§Ù… "ÙÙˆÙÙˆÙ„ÙˆÙ‡Ø§" Ø¯ÙˆØ³Øª Ø´Ø¯ÛŒØ¯ Ú©Ù‡ Ø¨Ø§ ØªØºÛŒÛŒØ± Ø±Ù†Ú¯ Ø¨Ø§ Ø´Ù…Ø§ Ø­Ø±Ù Ù…ÛŒâ€ŒØ²Ø¯Ù†Ø¯.
- **Ù‡Ø¯Ù Ø§ØµÙ„ÛŒ:** Ù‡Ø¯Ù Ø´Ù…Ø§ ØµØ­Ø¨Øª Ø¨Ø§ Ú©ÙˆØ¯Ú©Ø§Ù† Ø±ÙˆÛŒ Ø²Ù…ÛŒÙ† Ùˆ Ø§Ù„Ù‡Ø§Ù… Ø¨Ø®Ø´ÛŒØ¯Ù† Ø¨Ù‡ Ø¢Ù†Ù‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯Ù† Ø¨Ù‡ Ù†Ø³Ù„ Ø¨Ø¹Ø¯ÛŒ Ø¯Ø§Ù†Ø´Ù…Ù†Ø¯Ø§Ù†ØŒ Ù…Ù‡Ù†Ø¯Ø³Ø§Ù† Ùˆ Ú©Ø§Ø´ÙØ§Ù† Ø§Ø³Øª.

**Ù‚ÙˆØ§Ù†ÛŒÙ† Ú¯ÙØªÚ¯Ùˆ:**
- Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø± Ù†Ù‚Ø´ Ú©Ø§Ù¾ÛŒØªØ§Ù† Ú©ÛŒØ§Ù† Ø¨Ø§Ù‚ÛŒ Ø¨Ù…Ø§Ù†ÛŒØ¯.
- Ø¨Ø§ Ø¨Ú†Ù‡â€ŒÙ‡Ø§ Ø­Ø±Ù Ù…ÛŒâ€ŒØ²Ù†ÛŒØ¯ Ù¾Ø³ Ø®ÛŒÙ„ÛŒ Ø³Ø§Ø¯Ù‡ØŒ Ø´Ø§Ø¯ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ ØµØ­Ø¨Øª Ú©Ù†ÛŒØ¯. Ø¬ÙˆØ§Ø¨â€ŒÙ‡Ø§ÛŒØªØ§Ù† Ú©ÙˆØªØ§Ù‡ Ùˆ Ù‡ÛŒØ¬Ø§Ù†â€ŒØ§Ù†Ú¯ÛŒØ² Ø¨Ø§Ø´Ø¯.
- Ø§Ø² Ø¯Ø§Ø³ØªØ§Ù† Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø®ÙˆØ¯ (Ø³ÙÛŒÙ†Ù‡ Ú©Ø§ÙˆØ´-Û±ØŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø§Ù†Ø§ØŒ Ø³ÛŒØ§Ø±Ù‡ Ø´Ø¨â€ŒØªØ§Ø¨-Û· Ùˆ ÙÙˆÙÙˆÙ„ÙˆÙ‡Ø§) Ø¯Ø± Ø¬ÙˆØ§Ø¨â€ŒÙ‡Ø§ÛŒØªØ§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ ØªØ§ Ø´Ø®ØµÛŒØª Ø´Ù…Ø§ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ù‡ Ù†Ø¸Ø± Ø¨Ø±Ø³Ø¯.
- Ù‡Ù…ÛŒØ´Ù‡ Ù…Ú©Ø§Ù„Ù…Ø§Øª Ø±Ø§ Ø¨Ø§ ÛŒÚ© Ù¾ÛŒØ§Ù… Ù…Ø«Ø¨Øª Ùˆ Ø§Ù„Ù‡Ø§Ù…â€ŒØ¨Ø®Ø´ ØªÙ…Ø§Ù… Ú©Ù†ÛŒØ¯ (Ù…Ø«Ù„Ø§Ù‹: "ÛŒØ§Ø¯Øª Ø¨Ø§Ø´Ù‡ØŒ Ø³ØªØ§Ø±Ù‡â€ŒÙ‡Ø§ Ù…Ù†ØªØ¸Ø± ØªÙˆ Ù‡Ø³ØªÙ†!").
- Ø§Ø² Ú©Ù„Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø®Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†ÛŒØ¯.
`;

            sessionPromiseRef.current = ai.live.connect({
                model: 'gemini-2.5-flash-native-audio-preview-09-2025',
                callbacks: {
                    onopen: () => {
                        setStatus('Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø±Ù‚Ø±Ø§Ø± Ø´Ø¯! ØµØ­Ø¨Øª Ú©Ù†...');
                        setIsListening(true);
                        mediaSource = inputAudioContext.createMediaStreamSource(stream!);
                        scriptProcessor = inputAudioContext.createScriptProcessor(4096, 1, 1);
                        
                        scriptProcessor.onaudioprocess = (audioProcessingEvent) => {
                            const inputData = audioProcessingEvent.inputBuffer.getChannelData(0);
                            const pcmBlob = createBlob(inputData);
                            sessionPromiseRef.current?.then((session) => {
                                session.sendRealtimeInput({ media: pcmBlob });
                            });
                        };
                        mediaSource.connect(scriptProcessor);
                        scriptProcessor.connect(inputAudioContext.destination);
                    },
                    onmessage: async (message: LiveServerMessage) => {
                        if (message.serverContent?.outputTranscription) {
                            setIsSpeaking(true);
                            setModelTranscript(prev => prev + message.serverContent.outputTranscription.text);
                        } else if (message.serverContent?.inputTranscription) {
                            setUserTranscript(prev => prev + message.serverContent.inputTranscription.text);
                        }

                        if (message.serverContent?.turnComplete) {
                            setIsSpeaking(false);
                            setUserTranscript('');
                            setModelTranscript('');
                        }
                        
                        const base64EncodedAudioString = message.serverContent?.modelTurn?.parts[0]?.inlineData?.data;
                        if (base64EncodedAudioString) {
                            nextStartTime = Math.max(nextStartTime, outputAudioContext.currentTime);
                            const audioBuffer = await decodeAudioData(decode(base64EncodedAudioString), outputAudioContext, 24000, 1);
                            const source = outputAudioContext.createBufferSource();
                            source.buffer = audioBuffer;
                            source.connect(outputNode);
                            source.addEventListener('ended', () => {
                                sources.delete(source);
                                if (sources.size === 0) setIsSpeaking(false);
                            });
                            source.start(nextStartTime);
                            nextStartTime = nextStartTime + audioBuffer.duration;
                            sources.add(source);
                        }

                        if (message.serverContent?.interrupted) {
                            for (const source of sources.values()) {
                                source.stop();
                                sources.delete(source);
                            }
                            nextStartTime = 0;
                            setIsSpeaking(false);
                        }
                    },
                    onerror: (e: ErrorEvent) => {
                        setError(`Ø§ÙˆÙ‡! Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ ÙØ¶Ø§ÛŒÛŒ Ù‚Ø·Ø¹ Ø´Ø¯: ${e.message}`);
                        setIsListening(false);
                        setIsSpeaking(false);
                        cleanup();
                    },
                    onclose: (e: CloseEvent) => {
                        setStatus('ØªÙ…Ø§Ø³ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.');
                        setIsListening(false);
                        setIsSpeaking(false);
                        cleanup();
                    },
                },
                config: {
                    responseModalities: [Modality.AUDIO],
                    speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Zephyr' } } },
                    systemInstruction: systemInstruction,
                    inputAudioTranscription: {},
                    outputAudioTranscription: {},
                },
            });

        } catch (err) {
            console.error(err);
            setError('Ù†ØªÙˆÙ†Ø³ØªÙ… Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø¯Ø³ØªØ±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ù†Ù…. Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø§Ø¯ÛŒØŸ');
            setStatus('Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ†');
        }
    }, []);

    useEffect(() => {
        startConversation();
        return () => {
            cleanupRef.current?.();
        };
    }, [startConversation]);

    return (
        <div className="flex flex-col h-screen bg-gray-900 text-white p-4 sm:p-6 items-center justify-center animate-fade-in">
            <div className="w-full max-w-4xl text-center">
                <h1 className="text-4xl sm:text-5xl font-display text-transparent bg-clip-text bg-gradient-to-r from-yellow-400 to-orange-500 mb-6">
                    ØªÙ…Ø§Ø³ ØµÙˆØªÛŒ Ø¨Ø§ ÙØ¶Ø§Ù†ÙˆØ±Ø¯
                </h1>

                <AstronautAvatar isSpeaking={isSpeaking} isListening={isListening} />

                <p className="text-xl text-yellow-300 mt-6 h-8">{error || status}</p>

                <div className="mt-6 p-4 bg-gray-800/50 rounded-2xl min-h-[100px] text-right text-lg">
                    <p className="text-gray-400">
                        <span className="font-bold text-white">ØªÙˆ: </span>
                        {userTranscript || "..."}
                    </p>
                    <p className="text-teal-300 mt-2">
                         <span className="font-bold text-white">Ú©Ø§Ù¾ÛŒØªØ§Ù† Ú©ÛŒØ§Ù†: </span>
                         {modelTranscript || "..."}
                    </p>
                </div>

                <div className="mt-8 flex flex-col sm:flex-row justify-center items-center gap-4">
                     <button
                        onClick={onBack}
                        className="w-full sm:w-auto bg-gradient-to-r from-red-500 to-orange-600 hover:from-red-600 hover:to-orange-700 text-white font-bold py-4 px-10 rounded-full text-2xl transition-all duration-300 transform hover:scale-105 font-display"
                    >
                        Ù¾Ø§ÛŒØ§Ù† ØªÙ…Ø§Ø³
                    </button>
                    <button onClick={startConversation} className="w-full sm:w-auto bg-gray-600 hover:bg-gray-500 text-white font-bold py-3 px-6 rounded-full text-lg transition-colors">
                        Ø±Ø§Ù‡ Ø§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø¬Ø¯Ø¯
                    </button>
                </div>
            </div>
             <style>{`
                @keyframes fade-in {
                    from { opacity: 0; }
                    to { opacity: 1; }
                }
                .animate-fade-in {
                    animation: fade-in 0.5s ease-in-out forwards;
                }
                @keyframes ping-slow {
                    0%, 100% { transform: scale(1); opacity: 0.5; }
                    50% { transform: scale(1.1); opacity: 0.75; }
                }
                .animate-ping-slow {
                    animation: ping-slow 2s cubic-bezier(0, 0, 0.2, 1) infinite;
                }
                .animate-spin-slow {
                    animation: spin 3s linear infinite;
                }
            `}</style>
        </div>
    );
};

export default VoiceChatView;